{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Machine Learning Models for prepared significant variables dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook I'm utilizing five Machine Learning algorithms and one Deep Learning algorithm on initially cleaned dataset. Making use of RandomizedSearch in pipelines to find out best hyperparameters for ML algorithms. I'll perform some additional preparations of dataset, divide into train and test subsets, encoding into numbers with pandas get_dummies and OrdinalEncoder, using StandardScaller for scaling, SMOTEENN to make classes equal and PCA to decrease amount of variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import (StandardScaler, \n",
    "                                   OrdinalEncoder, \n",
    "                                   MinMaxScaler)\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, \n",
    "                                     GridSearchCV, \n",
    "                                     StratifiedKFold, \n",
    "                                     RandomizedSearchCV)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             roc_auc_score, \n",
    "                             make_scorer, \n",
    "                             recall_score, \n",
    "                             confusion_matrix, \n",
    "                             accuracy_score,\n",
    "                            get_scorer_names)\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.read_pickle(\"data/data_clear.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing into predictor variables X and target y (\"is_canceled\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_clean.drop(\"is_canceled\", axis=1)\n",
    "y = data_clean.is_canceled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into train and test subsets with test size 30% and train 70%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape after division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83573, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35817, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputting NaNs in country column with the most frequent value ()max of train subset into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_input = X_train[\"country\"][X_train.country.value_counts().max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.country.fillna(country_input, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.country.fillna(country_input, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputting NaNs in agent column with the most frequent value ()max of train subset into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_input = X_train[\"country\"][X_train.agent.value_counts().max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.agent.fillna(agent_input, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.agent.fillna(agent_input, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier value of column adr found in a file \"Data_Preparations\" now is to be replaced with mean of adr column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train[\"adr\"]==5400).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test[\"adr\"]==5400).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (X_train[\"adr\"]==5400).sum() > 0:\n",
    "    X_train.replace({5400.0:np.round(X_train.adr.mean(), 2)}, inplace=True) #filling inordinary adr value with mean of training set adr column\n",
    "    print(\"Outlier observations in train subset = \", (X_train[\"adr\"]==5400).sum())\n",
    "elif (X_test[\"adr\"]==5400).sum() > 0:\n",
    "    X_test.replace({5400.0:np.round(X_train.adr.mean(), 2)}, inplace=True)\n",
    "    print(\"Outlier observations in test subset = \", (X_test[\"adr\"]==5400).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding columns of most numerous classes with OrdinalEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_train = X_train[[\"agent\", \"company\", \"country\", \"reservation_status_date\", \"arrival_date\"]]\n",
    "data_label_test = X_test[[\"agent\", \"company\", \"country\", \"reservation_status_date\", \"arrival_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ode.fit(data_label_train)\n",
    "data_label_train_ode = pd.DataFrame(ode.transform(data_label_train),\n",
    "                                    columns=[\"agent\", \"company\", \"country\", \"reservation_status_date\", \"arrival_date\"])\n",
    "data_label_test_ode = pd.DataFrame(ode.transform(data_label_test), \n",
    "                                   columns=[\"agent\", \"company\", \"country\", \"reservation_status_date\", \"arrival_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_label_train_ode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([\"agent\", \"company\", \"country\", \"reservation_status_date\", \"arrival_date\"], axis=1, inplace=True)\n",
    "X_test.drop([\"agent\", \"company\", \"country\", \"reservation_status_date\", \"arrival_date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train.reset_index(drop=True), data_label_train_ode.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), data_label_test_ode.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding training and test subsets with get_dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test = X_test.reindex(columns = X_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating StandardScaler for further data scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating Principal Components with ten components reducing dimentions to ten components :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating algorithm to ballance unballanced data- SMOTEENN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTEEN = SMOTEENN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)\n",
    "#imbpipeline\n",
    "pipeline_rf = imbpipeline(steps=[\n",
    "    ['scaler', scaler],\n",
    "    ['pca', pca],\n",
    "    ['smote', SMOTEEN],\n",
    "    ['rf', RandomForestClassifier()]])\n",
    "    \n",
    "param_distributions_rf = {\n",
    "    'rf__n_estimators': [20, 100, 300],\n",
    "    'rf__max_depth': [10, 20],\n",
    "    'rf__min_samples_split': [5, 10],\n",
    "    'pca__n_components': [5, 10, 20]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(pipeline_rf, \n",
    "                               param_distributions_rf, \n",
    "                               n_iter=10, \n",
    "                               cv=stratified_kfold, \n",
    "                               scoring='roc_auc',\n",
    "                               verbose=3\n",
    "                              )\n",
    "\n",
    "search_rf.fit(X_train, y_train)\n",
    "y_pred_rf = search_rf.best_estimator_.predict(X_test)\n",
    "print(\"Random Forest:\")\n",
    "print(search_rf.best_params_)\n",
    "print(f'Results on test: {search_rf.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_rf.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(get_scorer_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_report_rf = pd.DataFrame(classification_report(y_test, y_pred_rf, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(A_report_rf.columns):\n",
    "  A_report_rf = A_report_rf.rename(columns={(A_report_rf.iloc[:,i].name): ('RF_'+A_report_xgb.iloc[:,i].name)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=13)\n",
    "\n",
    "pipeline = imbpipeline(steps = [['scaler', scaler],\n",
    "                                ['pca', pca],\n",
    "                                ['smote', SMOTEEN],\n",
    "                                ['dtc', DecisionTreeClassifier()]])\n",
    "\n",
    "    \n",
    "param_grid = {'dtc__max_leaf_nodes' : [2, 5, 10, 30], \n",
    "             'dtc__max_depth': [4, 10, 20, 40],\n",
    "             'dtc__random_state' : [23],\n",
    "             'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "\n",
    "search_dtc = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,                           \n",
    "                          verbose=3,\n",
    "                           #n_jobs=3\n",
    "                         )\n",
    "\n",
    "search_dtc.fit(X_train, y_train)\n",
    "y_pred_dtc = search_dtc.best_estimator_.predict(X_test)\n",
    "cv_score = search_dtc.best_score_\n",
    "test_score = search_dtc.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"Decision Tree:\")\n",
    "print(search_rf.best_params_)\n",
    "print(f'Results on test: {search_rf.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_rf.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dtc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_dtc))\n",
    "A_report_dtc = pd.DataFrame(classification_report(y_test, y_pred_dtc, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(A_report_dtc.columns):\n",
    "  A_report_dtc = A_report_dtc.rename(columns={(A_report_dtc.iloc[:,i].name): ('DTC_'+A_report_dtc.iloc[:,i].name)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_dtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=23)\n",
    "\n",
    "pipeline_SVC = imbpipeline([('scaler', scaler),\n",
    "                            ('pca', pca),\n",
    "                            ('SMOTE', SMOTEEN),\n",
    "                            ('SVC', SVC())])\n",
    "    \n",
    "params_SVC = {\n",
    "              'SVC__gamma': ['auto'],\n",
    "              'SVC__max_iter': [150, 300, 500],\n",
    "              'SVC__decision_function_shape': ['ovo'],\n",
    "              'SVC__degree': [1],\n",
    "              'SVC__kernel': ['rbf'],\n",
    "              'SVC__random_state': [11],\n",
    "              'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "\n",
    "search_SVC = GridSearchCV(pipeline_SVC,\n",
    "                             params_SVC,\n",
    "                             scoring='roc_auc',\n",
    "                             cv=stratified_kfold,\n",
    "                            verbose=3,\n",
    "                            #n_jobs=3\n",
    "                         )\n",
    "\n",
    "search_SVC.fit(X_train, y_train)\n",
    "\n",
    "cv_score = search_SVC.best_score_\n",
    "test_score = search_SVC.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"Support Vector:\")\n",
    "print(search_SVC.best_params_)\n",
    "print(f'Results on test: {search_SVC.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_SVC.best_estimator_.score(X_train, y_train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVC_train = search_SVC.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc_test = search_SVC.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVC = search_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_SVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_SVC))\n",
    "A_report_svc = pd.DataFrame(classification_report(y_test, y_pred_SVC, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(A_report_svc.columns):\n",
    "  A_report_svc = A_report_svc.rename(columns={(A_report_svc.iloc[:,i].name): ('SVC_'+A_report_svc.iloc[:,i].name)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=77)\n",
    "\n",
    "pipeline = imbpipeline(steps=[('scaler', scaler),\n",
    "                              ('pca', pca),\n",
    "                              ('smote', SMOTEEN),\n",
    "                              ('XGB', XGBClassifier())])\n",
    "\n",
    "params = {\n",
    "    'XGB__n_estimators': [100, 500, 800],\n",
    "    'XGB__max_depth': [3, 5, 10],\n",
    "    'XGB__learning_rate': [0.1, 0.5],\n",
    "    'pca__n_components': [5, 10, 20]\n",
    "    }\n",
    "\n",
    "search_XGB = GridSearchCV(pipeline, \n",
    "                          params, \n",
    "                          scoring='roc_auc', \n",
    "                          cv=stratified_kfold, \n",
    "                          verbose=3,\n",
    "                        #n_jobs=3\n",
    "                         ) \n",
    "\n",
    "search_XGB.fit(X_train, y_train) \n",
    "accuracy_score(y_test, search_XGB.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_XGB.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, search_XGB.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = search_XGB.best_estimator_.predict(X_test)\n",
    "test_score = search_XGB.score(X_test, y_test)\n",
    "cv_score = search_XGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"XGBClassifier:\")\n",
    "print(search_XGB.best_params_)\n",
    "print(f'Results on test: {search_XGB.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_XGB.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_XGB))\n",
    "A_report_xgb = pd.DataFrame(classification_report(y_test, y_pred_XGB, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(A_report_xgb.columns):\n",
    "  A_report_xgb = A_report_xgb.rename(columns={(A_report_xgb.iloc[:,i].name): ('XGB_'+A_report_xgb.iloc[:,i].name)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['scaler', scaler],\n",
    "                                ['pca', pca],\n",
    "                                ['smote', SMOTEEN],\n",
    "                                ['LR', LogisticRegression()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=13)\n",
    "    \n",
    "param_grid = {'LR__C':[20, 50, 70],\n",
    "             'LR__random_state': [11],\n",
    "             'LR__multi_class': ['auto'],\n",
    "             'LR__max_iter': [100, 200, 500],\n",
    "             'LR__solver': ['saga'],\n",
    "             'LR__penalty': ['l2', 'l1'],\n",
    "             'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "                                                                 \n",
    "search_LR = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose=3,\n",
    "                           #n_jobs=3\n",
    "                        )\n",
    "\n",
    "search_LR.fit(X_train, y_train)\n",
    "cv_score = search_LR.best_score_\n",
    "test_score = search_LR.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"XGBClassifier:\")\n",
    "print(search_LR.best_params_)\n",
    "print(f'Results on test: {search_LR.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_LR.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = search_LR.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr))\n",
    "A_report_lr = pd.DataFrame(classification_report(y_test, y_pred_lr, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(A_report_lr.columns):\n",
    "  A_report_lr = A_report_lr.rename(columns={(A_report_lr.iloc[:,i].name): ('LR_'+A_report_lr.iloc[:,i].name)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing Multi Layer Perceptron algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['scaler', scaler],\n",
    "                                ['pca', pca],\n",
    "                                ['smote', SMOTEEN],\n",
    "                                ['MLP', MLPClassifier()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=13)\n",
    "    \n",
    "param_grid = {'MLP__hidden_layer_sizes':[8, 4, 16],\n",
    "             'MLP__activation': ['relu'],\n",
    "              'MLP__solver': ['adam'],\n",
    "              'MLP__random_state': [42],\n",
    "              'MLP__max_iter': [1000],\n",
    "              'MLP__batch_size': [32],\n",
    "              'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "                                                                 \n",
    "search_MLP = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose=3,\n",
    "                           #n_jobs=3\n",
    "                        )\n",
    "\n",
    "search_MLP.fit(X_train, y_train)\n",
    "cv_score = search_MLP.best_score_\n",
    "test_score = search_MLP.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_MLP.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = search_MLP.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "A_report_mlp = pd.DataFrame(classification_report(y_test, y_pred_mlp, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(A_report_mlp.columns):\n",
    "  A_report_mlp = A_report_mlp.rename(columns={(A_report_mlp.iloc[:,i].name): ('MLP_'+A_report_mlp.iloc[:,i].name)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Data Frame containing all six classifiers results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_results = pd.concat([A_report_rf, \n",
    "                       A_report_dtc, \n",
    "                       A_report_svc, \n",
    "                       A_report_xgb, \n",
    "                       A_report_lr, \n",
    "                       A_report_mlp], \n",
    "                      axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving results in a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_results.to_pickle(\"data/A_dataset_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_results = pd.read_pickle(\"data/A_dataset_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_0</th>\n",
       "      <th>RF_1</th>\n",
       "      <th>RF_accuracy</th>\n",
       "      <th>RF_macro avg</th>\n",
       "      <th>RF_weighted avg</th>\n",
       "      <th>DTC_0</th>\n",
       "      <th>DTC_1</th>\n",
       "      <th>DTC_accuracy</th>\n",
       "      <th>DTC_macro avg</th>\n",
       "      <th>DTC_weighted avg</th>\n",
       "      <th>...</th>\n",
       "      <th>LR_0</th>\n",
       "      <th>LR_1</th>\n",
       "      <th>LR_accuracy</th>\n",
       "      <th>LR_macro avg</th>\n",
       "      <th>LR_weighted avg</th>\n",
       "      <th>MLP_0</th>\n",
       "      <th>MLP_1</th>\n",
       "      <th>MLP_accuracy</th>\n",
       "      <th>MLP_macro avg</th>\n",
       "      <th>MLP_weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.798638</td>\n",
       "      <td>0.791443</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.795041</td>\n",
       "      <td>0.795973</td>\n",
       "      <td>0.801758</td>\n",
       "      <td>0.639499</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>0.741656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830833</td>\n",
       "      <td>0.651304</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>0.741069</td>\n",
       "      <td>0.764334</td>\n",
       "      <td>0.826294</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.810006</td>\n",
       "      <td>0.801342</td>\n",
       "      <td>0.807809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.905100</td>\n",
       "      <td>0.612120</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.758610</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.776585</td>\n",
       "      <td>0.673626</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>0.725106</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768825</td>\n",
       "      <td>0.733926</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>0.751376</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>0.884080</td>\n",
       "      <td>0.684103</td>\n",
       "      <td>0.810006</td>\n",
       "      <td>0.784092</td>\n",
       "      <td>0.810006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.848543</td>\n",
       "      <td>0.690326</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.769435</td>\n",
       "      <td>0.789938</td>\n",
       "      <td>0.788971</td>\n",
       "      <td>0.656119</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>0.722545</td>\n",
       "      <td>0.739761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798627</td>\n",
       "      <td>0.690151</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>0.744389</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.854211</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.810006</td>\n",
       "      <td>0.790771</td>\n",
       "      <td>0.807213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>22550.000000</td>\n",
       "      <td>13267.000000</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>22550.000000</td>\n",
       "      <td>13267.000000</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22550.000000</td>\n",
       "      <td>13267.000000</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>22550.000000</td>\n",
       "      <td>13267.000000</td>\n",
       "      <td>0.810006</td>\n",
       "      <td>35817.000000</td>\n",
       "      <td>35817.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RF_0          RF_1  RF_accuracy  RF_macro avg  \\\n",
       "precision      0.798638      0.791443     0.796577      0.795041   \n",
       "recall         0.905100      0.612120     0.796577      0.758610   \n",
       "f1-score       0.848543      0.690326     0.796577      0.769435   \n",
       "support    22550.000000  13267.000000     0.796577  35817.000000   \n",
       "\n",
       "           RF_weighted avg         DTC_0         DTC_1  DTC_accuracy  \\\n",
       "precision         0.795973      0.801758      0.639499      0.738448   \n",
       "recall            0.796577      0.776585      0.673626      0.738448   \n",
       "f1-score          0.789938      0.788971      0.656119      0.738448   \n",
       "support       35817.000000  22550.000000  13267.000000      0.738448   \n",
       "\n",
       "           DTC_macro avg  DTC_weighted avg  ...          LR_0          LR_1  \\\n",
       "precision       0.720629          0.741656  ...      0.830833      0.651304   \n",
       "recall          0.725106          0.738448  ...      0.768825      0.733926   \n",
       "f1-score        0.722545          0.739761  ...      0.798627      0.690151   \n",
       "support     35817.000000      35817.000000  ...  22550.000000  13267.000000   \n",
       "\n",
       "           LR_accuracy  LR_macro avg  LR_weighted avg         MLP_0  \\\n",
       "precision     0.755898      0.741069         0.764334      0.826294   \n",
       "recall        0.755898      0.751376         0.755898      0.884080   \n",
       "f1-score      0.755898      0.744389         0.758447      0.854211   \n",
       "support       0.755898  35817.000000     35817.000000  22550.000000   \n",
       "\n",
       "                  MLP_1  MLP_accuracy  MLP_macro avg  MLP_weighted avg  \n",
       "precision      0.776390      0.810006       0.801342          0.807809  \n",
       "recall         0.684103      0.810006       0.784092          0.810006  \n",
       "f1-score       0.727331      0.810006       0.790771          0.807213  \n",
       "support    13267.000000      0.810006   35817.000000      35817.000000  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
