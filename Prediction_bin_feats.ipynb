{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this file I present creating models with pipelines comparing results of cross-validated hyperparameters to achive best model's fitting on binned dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import (StandardScaler, \n",
    "                                   OrdinalEncoder, \n",
    "                                   MinMaxScaler)\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, \n",
    "                                     GridSearchCV, \n",
    "                                     StratifiedKFold, \n",
    "                                     RandomizedSearchCV)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             roc_auc_score, \n",
    "                             make_scorer, \n",
    "                             recall_score, \n",
    "                             confusion_matrix, \n",
    "                             accuracy_score,\n",
    "                            get_scorer_names)\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.read_pickle(\"data/data_bins.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47019</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>zero</td>\n",
       "      <td>one_night</td>\n",
       "      <td>1</td>\n",
       "      <td>No_child</td>\n",
       "      <td>No_babies</td>\n",
       "      <td>BB</td>\n",
       "      <td>Hi-Freq</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>PRT</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient-Party</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>2016-02-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25495</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>one_night</td>\n",
       "      <td>more</td>\n",
       "      <td>2</td>\n",
       "      <td>No_child</td>\n",
       "      <td>No_babies</td>\n",
       "      <td>BB</td>\n",
       "      <td>Freq</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>243.0</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>64.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016-06-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50279</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>zero</td>\n",
       "      <td>one_night</td>\n",
       "      <td>2</td>\n",
       "      <td>No_child</td>\n",
       "      <td>No_babies</td>\n",
       "      <td>BB</td>\n",
       "      <td>Hi-Freq</td>\n",
       "      <td>...</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>1.0</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>2016-04-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>one_night</td>\n",
       "      <td>more</td>\n",
       "      <td>2</td>\n",
       "      <td>No_child</td>\n",
       "      <td>No_babies</td>\n",
       "      <td>BB</td>\n",
       "      <td>Freq</td>\n",
       "      <td>...</td>\n",
       "      <td>Refundable</td>\n",
       "      <td>PRT</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient-Party</td>\n",
       "      <td>70.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>2016-05-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112945</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>one_night</td>\n",
       "      <td>more</td>\n",
       "      <td>2</td>\n",
       "      <td>No_child</td>\n",
       "      <td>No_babies</td>\n",
       "      <td>HB</td>\n",
       "      <td>Lo_freq</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>9.0</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>162.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2017-05-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               hotel  is_canceled  lead_time stays_in_weekend_nights  \\\n",
       "47019     City Hotel            1         31                    zero   \n",
       "25495   Resort Hotel            0        157               one_night   \n",
       "50279     City Hotel            1        295                    zero   \n",
       "6081    Resort Hotel            0        223               one_night   \n",
       "112945    City Hotel            0        174               one_night   \n",
       "\n",
       "       stays_in_week_nights  adults  children     babies meal  country  ...  \\\n",
       "47019             one_night       1  No_child  No_babies   BB  Hi-Freq  ...   \n",
       "25495                  more       2  No_child  No_babies   BB     Freq  ...   \n",
       "50279             one_night       2  No_child  No_babies   BB  Hi-Freq  ...   \n",
       "6081                   more       2  No_child  No_babies   BB     Freq  ...   \n",
       "112945                 more       2  No_child  No_babies   HB  Lo_freq  ...   \n",
       "\n",
       "       deposit_type  agent  company  days_in_waiting_list    customer_type  \\\n",
       "47019    No Deposit    PRT    174.0                     0  Transient-Party   \n",
       "25495    No Deposit  243.0    empty                     0         Contract   \n",
       "50279    Non Refund    1.0    empty                     0        Transient   \n",
       "6081     Refundable    PRT    223.0                     0  Transient-Party   \n",
       "112945   No Deposit    9.0    empty                     0        Transient   \n",
       "\n",
       "           adr required_car_parking_spaces  total_of_special_requests  \\\n",
       "47019    71.00                           0                          0   \n",
       "25495    64.90                           0                          1   \n",
       "50279    62.00                           0                          0   \n",
       "6081     70.29                           1                          0   \n",
       "112945  162.00                           0                          2   \n",
       "\n",
       "       reservation_status_date         arrival_date  \n",
       "47019               2016-02-04  2016-02-04 00:00:00  \n",
       "25495               2016-06-30  2016-06-23 00:00:00  \n",
       "50279               2015-10-21  2016-04-28 00:00:00  \n",
       "6081                2016-05-31  2016-05-24 00:00:00  \n",
       "112945              2017-05-31  2017-05-26 00:00:00  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing into predictor variables X and target y (\"is_canceled\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_clean.drop(\"is_canceled\", axis=1)\n",
    "y = data_clean.is_canceled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into train and test subsets with test size 30% and train 70%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape after division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83573, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35817, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier value of column adr found in a file \"Reservation_Cancelation_Prediction\" now is to be replaced with mean of adr column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[\"adr\"]==5400).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test[\"adr\"]==5400).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abnormal observations in train subset =  0\n"
     ]
    }
   ],
   "source": [
    "if (X_train[\"adr\"]==5400).sum() > 0:\n",
    "    X_train.replace({5400.0:np.round(X_train.adr.mean(), 2)}, inplace=True) #filling inordinary adr value with mean of training set adr column\n",
    "    print(\"Outlier observations in train subset = \", (X_train[\"adr\"]==5400).sum())\n",
    "elif (X_test[\"adr\"]==5400).sum() > 0:\n",
    "    X_test.replace({5400.0:np.round(X_train.adr.mean(), 2)}, inplace=True)\n",
    "    print(\"Outlier observations in test subset = \", (X_test[\"adr\"]==5400).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorial columns with OrdinalEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_clean.select_dtypes([\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_train = X_train[data_cat]\n",
    "data_label_test = X_test[data_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ode.fit(data_label_train)\n",
    "data_label_train_ode = pd.DataFrame(ode.transform(data_label_train),\n",
    "                                    columns=data_cat)\n",
    "data_label_test_ode = pd.DataFrame(ode.transform(data_label_test), \n",
    "                                   columns=data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal</th>\n",
       "      <th>country</th>\n",
       "      <th>market_segment</th>\n",
       "      <th>distribution_channel</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83570</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83573 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hotel  stays_in_weekend_nights  stays_in_week_nights  children  babies  \\\n",
       "0        0.0                      2.0                   1.0       0.0     0.0   \n",
       "1        1.0                      2.0                   1.0       0.0     0.0   \n",
       "2        1.0                      2.0                   2.0       0.0     0.0   \n",
       "3        1.0                      2.0                   0.0       0.0     0.0   \n",
       "4        1.0                      2.0                   1.0       0.0     0.0   \n",
       "...      ...                      ...                   ...       ...     ...   \n",
       "83568    0.0                      1.0                   1.0       0.0     0.0   \n",
       "83569    0.0                      2.0                   1.0       0.0     0.0   \n",
       "83570    1.0                      2.0                   0.0       0.0     0.0   \n",
       "83571    0.0                      2.0                   1.0       0.0     0.0   \n",
       "83572    1.0                      2.0                   0.0       0.0     0.0   \n",
       "\n",
       "       meal  country  market_segment  distribution_channel  \\\n",
       "0       0.0      1.0             4.0                   2.0   \n",
       "1       0.0      1.0             4.0                   2.0   \n",
       "2       0.0      1.0             3.0                   2.0   \n",
       "3       0.0      0.0             2.0                   1.0   \n",
       "4       0.0      1.0             1.0                   1.0   \n",
       "...     ...      ...             ...                   ...   \n",
       "83568   0.0      2.0             2.0                   2.0   \n",
       "83569   0.0      1.0             2.0                   2.0   \n",
       "83570   0.0      2.0             4.0                   2.0   \n",
       "83571   0.0      1.0             2.0                   2.0   \n",
       "83572   0.0      0.0             2.0                   1.0   \n",
       "\n",
       "       reserved_room_type  assigned_room_type  deposit_type  agent  company  \\\n",
       "0                     0.0                 0.0           0.0  288.0    323.0   \n",
       "1                     0.0                 3.0           0.0   98.0    323.0   \n",
       "2                     3.0                 4.0           0.0  316.0     92.0   \n",
       "3                     0.0                 0.0           0.0  316.0     76.0   \n",
       "4                     4.0                 4.0           0.0  316.0    323.0   \n",
       "...                   ...                 ...           ...    ...      ...   \n",
       "83568                 0.0                 0.0           0.0    0.0    323.0   \n",
       "83569                 0.0                 0.0           1.0  143.0    323.0   \n",
       "83570                 4.0                 4.0           0.0   99.0    323.0   \n",
       "83571                 0.0                 0.0           1.0  193.0    323.0   \n",
       "83572                 0.0                 0.0           0.0  316.0     76.0   \n",
       "\n",
       "       customer_type  reservation_status_date  arrival_date  \n",
       "0                2.0                    400.0         562.0  \n",
       "1                2.0                    375.0         258.0  \n",
       "2                3.0                    886.0         770.0  \n",
       "3                3.0                    449.0         330.0  \n",
       "4                2.0                    714.0         597.0  \n",
       "...              ...                      ...           ...  \n",
       "83568            3.0                    339.0         220.0  \n",
       "83569            2.0                    640.0         660.0  \n",
       "83570            2.0                    817.0         699.0  \n",
       "83571            2.0                    304.0         231.0  \n",
       "83572            3.0                    449.0         328.0  \n",
       "\n",
       "[83573 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label_train_ode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['hotel', 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'babies', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'agent', 'company', 'customer_type', 'reservation_status_date', 'arrival_date'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-32714d31aafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5386\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5387\u001b[0m         \"\"\"\n\u001b[0;32m-> 5388\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5389\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5390\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6974\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6975\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6976\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6977\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['hotel', 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'babies', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'agent', 'company', 'customer_type', 'reservation_status_date', 'arrival_date'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X_train.drop(data_cat, axis=1, inplace=True)\n",
    "X_test.drop(data_cat, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating encoded features with the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train.reset_index(drop=True), data_label_train_ode.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), data_label_test_ode.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83573, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding with get_dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test = X_test.reindex(columns = X_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83573, 27)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating StandardScaler for further data scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating Principal Components with ten components reducing dimentions to ten components :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating algorithm to ballance unballanced data- SMOTEENN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTEEN = SMOTEENN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)\n",
    "#imbpipeline\n",
    "pipeline_rf = imbpipeline(steps=[\n",
    "    ['scaler', scaler],\n",
    "    ['pca', pca],\n",
    "    ['smote', SMOTEEN],\n",
    "    ['rf', RandomForestClassifier()]])\n",
    "    \n",
    "param_distributions_rf = {\n",
    "    'rf__n_estimators': [20, 100, 300],\n",
    "    'rf__max_depth': [10, 20],\n",
    "    'rf__min_samples_split': [5, 10],\n",
    "    'pca__n_components': [5, 10, 20]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(pipeline_rf, \n",
    "                               param_distributions_rf, \n",
    "                               n_iter=10, \n",
    "                               cv=stratified_kfold, \n",
    "                               scoring='roc_auc',\n",
    "                               verbose=3\n",
    "                              )\n",
    "\n",
    "search_rf.fit(X_train, y_train)\n",
    "y_pred_rf = search_rf.best_estimator_.predict(X_test)\n",
    "print(\"Random Forest:\")\n",
    "print(search_rf.best_params_)\n",
    "print(f'Results on test: {search_rf.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_rf.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(get_scorer_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_report_rf = pd.DataFrame(classification_report(y_test, y_pred_rf, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=13)\n",
    "\n",
    "pipeline = imbpipeline(steps = [['scaler', scaler],\n",
    "                                ['pca', pca],\n",
    "                                ['smote', SMOTEEN],\n",
    "                                ['dtc', DecisionTreeClassifier()]])\n",
    "\n",
    "    \n",
    "param_grid = {'dtc__max_leaf_nodes' : [2, 5, 10, 30], \n",
    "             'dtc__max_depth': [4, 10, 20, 40],\n",
    "             'dtc__random_state' : [23],\n",
    "             'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "\n",
    "search_dtc = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,                           \n",
    "                          verbose=3,\n",
    "                           #n_jobs=3\n",
    "                         )\n",
    "\n",
    "search_dtc.fit(X_train, y_train)\n",
    "y_pred_dtc = search_dtc.best_estimator_.predict(X_test)\n",
    "cv_score = search_dtc.best_score_\n",
    "test_score = search_dtc.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"Decision Tree:\")\n",
    "print(search_rf.best_params_)\n",
    "print(f'Results on test: {search_rf.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_rf.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_dtc))\n",
    "A_report_dtc = pd.DataFrame(classification_report(y_test, y_pred_dtc, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f8578aca648f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                        random_state=23)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m pipeline_SVC = imbpipeline([('scaler', scaler),\n\u001b[0m\u001b[1;32m      6\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0;34m'SMOTE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMOTEEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=23)\n",
    "\n",
    "pipeline_SVC = imbpipeline([('scaler', scaler),\n",
    "                            ('pca', pca),\n",
    "                            ('SMOTE', SMOTEEN),\n",
    "                            ('SVC', SVC())])\n",
    "    \n",
    "params_SVC = {\n",
    "              'SVC__gamma': ['auto'],# [10, 20, 50]\n",
    "              'SVC__max_iter': [150, 300, 500],\n",
    "              'SVC__decision_function_shape': ['ovo'],\n",
    "              'SVC__degree': [1], #, 3, 5],\n",
    "              'SVC__kernel': ['rbf'],\n",
    "              'SVC__random_state': [11],\n",
    "              'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "\n",
    "search_SVC = GridSearchCV(pipeline_SVC,\n",
    "                             params_SVC,\n",
    "                             scoring='roc_auc',\n",
    "                             cv=stratified_kfold,\n",
    "                            verbose=3,\n",
    "                            #n_jobs=3\n",
    "                         )\n",
    "\n",
    "search_SVC.fit(X_train, y_train)\n",
    "\n",
    "cv_score = search_SVC.best_score_\n",
    "test_score = search_SVC.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"Support Vector:\")\n",
    "print(search_SVC.best_params_)\n",
    "print(f'Results on test: {search_SVC.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_SVC.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVC_train = search_SVC.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc_test = search_SVC.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVC = search_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_SVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_SVC))\n",
    "A_report_svc = pd.DataFrame(classification_report(y_test, y_pred_SVC, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_report_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(classification_report(y_test, y_pred_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=77)\n",
    "\n",
    "pipeline = imbpipeline(steps=[('scaler', scaler),\n",
    "                              ('pca', pca),\n",
    "                              ('smote', SMOTEEN),\n",
    "                              ('XGB', XGBClassifier())])\n",
    "\n",
    "params = {\n",
    "    'XGB__n_estimators': [100, 300, 500, 800],\n",
    "    'XGB__max_depth': [3, 5, 7, 10],\n",
    "    'XGB__learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "    'pca__n_components': [5, 10, 20]\n",
    "    }\n",
    "\n",
    "search_XGB = GridSearchCV(pipeline, \n",
    "                          params, \n",
    "                          scoring='roc_auc', \n",
    "                          cv=stratified_kfold, \n",
    "                          verbose=3,\n",
    "                        #n_jobs=3\n",
    "                         ) \n",
    "\n",
    "search_XGB.fit(X_train, y_train)\n",
    "accuracy_score(y_test, search_XGB.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_XGB.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = search_XGB.best_estimator_.predict(X_test)\n",
    "test_score = search_XGB.score(X_test, y_test)\n",
    "cv_score = search_XGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(\"XGBClassifier:\")\n",
    "print(search_XGB.best_params_)\n",
    "print(f'Results on test: {search_XGB.best_estimator_.score(X_test, y_test)}')\n",
    "print(f'Results on train: {search_XGB.best_estimator_.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_XGB))\n",
    "A_report_xgb = pd.DataFrame(classification_report(y_test, y_pred_XGB, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['scaler', scaler],\n",
    "                                ['pca', pca],\n",
    "                                ['smote', SMOTEEN],\n",
    "                                ['LR', LogisticRegression()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=13)\n",
    "    \n",
    "param_grid = {'LR__C':[20, 50, 70, 80],\n",
    "             'LR__random_state': [11],\n",
    "             'LR__multi_class': ['auto'],\n",
    "             'LR__max_iter': [12, 25, 50, 100],\n",
    "             'LR__solver': ['saga'],\n",
    "             'LR__penalty': ['l2', 'l1'],\n",
    "             'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "                                                                 \n",
    "search_LR = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose=3,\n",
    "                           #n_jobs=3\n",
    "                        )\n",
    "\n",
    "search_LR.fit(X_train, y_train)\n",
    "cv_score = search_LR.best_score_\n",
    "test_score = search_LR.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = search_LR.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = search_LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr))\n",
    "A_report_rl = pd.DataFrame(classification_report(y_test, y_pred_lr, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing Multi Layer Perceptron algorythm with RandomizedGridSearch in pipeline, scaling reducing, ballancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['scaler', scaler],\n",
    "                                ['pca', pca],\n",
    "                                ['smote', SMOTEEN],\n",
    "                                ['MLP', MLPClassifier()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=13)\n",
    "    \n",
    "param_grid = {'MLP__hidden_layer_sizes':[8, 4, 16],\n",
    "             'MLP__activation': ['relu'],\n",
    "              'MLP__solver': ['adam'],\n",
    "              'MLP__random_state': [42],\n",
    "              'MLP__max_iter': [1000],\n",
    "              'MLP__batch_size': [32],\n",
    "              'pca__n_components': [5, 10, 20]\n",
    "             }\n",
    "                                                                 \n",
    "search_MLP = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose=3,\n",
    "                           #n_jobs=3\n",
    "                        )\n",
    "\n",
    "search_MLP.fit(X_train, y_train)\n",
    "cv_score = search_MLP.best_score_\n",
    "test_score = search_MLP.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving scores of classification, saving accuracy, recall and F1 score in data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = MLP.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "A_report_mlp = pd.DataFrame(classification_report(y_test, y_pred_mlp, output_dict=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
